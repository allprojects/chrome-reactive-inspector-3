\chapter{Evaluation}
In this chapter we evaluate the contributions of this thesis and the general state of the project. On that account we first examine the changes to the UI, the Source Code Previews and performance improvements. We then verify the most important features of CRI by checking a set of specification for each test application and discuss the result. %TODO check if grammar is okay


\section{Evaluation of Improvements}
	\subsection{Changes to the User Interface}
	Most of the changes to the User Interface are, by their nature, hard to evaluate in regards to their usability improvement. The experienced usability of a User Interface can be highly subjective \cite, the easiest way to achieve consistent evaluation results is therefore by collecting and analyzing empirical data, for example through Click stream analysis \cite{Clickstream}. Since CRI is not yet used in active production systems by a large user base, a User Study would be the usual approach. Unfortunately this is outside the scope of this thesis. However, some changes can be verified as improvements. For example, the text per node in the Dependency Graph was reduced without loosing any information can be seen as a general improvement of usability, because the change did not affect any other part of the UI and removed obsolete text. Another change that can be objectively categorized as an improvement is that parts of the UI which are not necessary to examine the Dependency Graph can now be hidden. Although it has to be noted that this change added a new UI element - the \emph{hide} button - which could potentially introduces new usability issues. Highlighting of the currently updated edge in addition to nodes also provides additional information for the user, to help track down differences between steps that were not as easily detectable before, without affecting other aspects of the UI.

	\subsection{"Code Previews"}
	% - since on-demand feature the performance impact is neglegent, additional storage of js files in RAM in non-instrumented form (to show code) is also neglegent due to RAM reduce of performance improvements.
	% - a robustness test is performed through checking the specification against all test apps
	% - percentage of nodes per test app that have them (details appendix):
	% Total Nodes: 581
	% Sum Source Infos: 436 = 75% of total nodes
	% Sum Named: 197 = 33.9% of total nodes
	% Additional 35.1% of total nodes have details attached that give context.
	% - most nodes that do not have source info are easy to identify because they are nodes created for fixed values like  for test app RxJs/canvas painting - node with id 9 is a ScalarObservable with value "#000000".
	% - short reference to specs in later section

	\subsection{"Performance improvements"}
	\label{sec:PerformanceEvaluation}
	% All measurements with integrated Web server of WebStorm on localhost. Chrome Version 64.0.3282.140 (Offizieller Build) (64-Bit). WebStorm 2017 3.4. Win10 8GB RAM i7 7500 2.7GHz 4CPUs, Intel(R) HD Graphics 620. No other active applications but background processes and services must be taken into account.
	
	% Memory and CPU for PerformanceTest with approx. equal conditions:
	% CRI3 -> stream approach: RAM is farily constant and not dependent on the number of steps in the history, although the impact is tiny since modern PCs have enough. -> Would already be achieved by paging.
	
	% Comparison CRI2 CRI3 on PerformanceTest
	% - Tests for CPU and RAM, tested on WebStorm integrated Web server by creating a breakpoint at nodeCreated[1], starting the recording with Chrome-JavaScript Profiler and Memory DevTool, and then resuming.
	% - results are approximations due to unknown influences by the OS and by manually controlling the start and end.
	% - memory test for CRI2 had to be restarted several times before it would complete the execution without crashing. Few forced UI updates by dragging the Dependency Graph around a few centimeters.
	
	%CPU:: "(program)" = native code of Chrome, Images are not very expressive since they cover the whole recording time and not only the execution time - they can only be used as vague indicators. The percentage of execution time to recording time can give a glimpse on the variance of the percentages in the images - however "(program") can not be judged by that - it is not visible if the "(program)" time was spent during execution or after/before due to the limitations of the recording tool.
 	% CRI2 - CPU:
 	% approx execution time by selecting the heavy loaded area in the "Chart" view: end 170000ms - start 16000ms =  154s
	% execution time percentage of recording: ~154000ms / 187860ms  * 100 ~= 82.0%
	% The biggest percentage directly correspond to UI updates - which happen at least once per created step since the slider is updated and renders the new Dependency Graph. getBB (getBoundingBox) calculates the size of the nodes in the graph, buildFragment's impact stems form domManip from jquery
	
	% CRI3 - CPU:
	% 13000ms - 7500ms = 5.5s, 
	% execution time percentage of recording: ~5500 / 23188ms * 100 ~= 23.7 %
	% it can be seen that still a sizeable part of cpu time is spent in UI related computation getBB (getBoundingBox). "ja" is a part of jquery and is hard to track down, but approx. half stems from dispatchOnMessage
	% the (program) part is the biggest chunk, but not visible what parts are due to running the profiling, running the test app, handling mediation etc.
	
	%RAM::
	% CRI2 - RAM: Total RAM approx 52.7MB
	% CRI3 -RAM: Total RAM approx 14.6MB
	% most notable difference in a category is the size of JS array which includes the most part of the stored Dependency Graph
	% Comparison to same Test app with pause event after 250ms instead of 5s:
	% CRI2: ~16.1MB -> increases rapidly over time
	% CRI3: ~12.6MB -> increases very little over time
	% for 250ms both version have a fairly similar Memory consumption, although CRI2 has a noticable delay before the Dependency Graph is shown (still <5s) while CRI3 has no noticeable delay.
	
	% example mario: still to fast to keep up - will crash if not paused
	% -> in case of mario - hard to detect the real reason due to overload of Chrome itself - the async requests on communication api seems to build up because they are to many for Chrome to keep up.
	% --> crashes CRI Chrome extension if not paused
	
	% Comparison for test case PerformanceTest: CRI vs RxFiddle
		% although RxFiddle does not have performance issues (lags > 1 s when hovering over a node) for ~ 1000 updates on Chrome. It does block Firefox (57.0.4 (64-bit)) for a few seconds. Once the UI is build it is noticeable slower than for applications with less value changes but delays < 1s. The CRI performance for this test app is slightly faster, but due to it being an extension instead of a webpage the performance difference may not be due to the tool implementations. CRI generates ~ 2700 steps, RxFiddle generates ~ 1000 values for each operator/observable in the chain of "intervalObservable".
		% CRI is not testable in Firefox
		
		
		
	
\section{"Current state of the Test Applications"}
	Specifications
	\begin{itemize}
		\item The dependency graph is shown and all observables that are assigned to a named variable are displayed distinctively.
		(Test: Up to the first five named observables in the code are all displayed with an orange background.)
		\item The history of the dependency graph can be navigated. It is possible to navigate to the previous, succeeding or a random step in the history. (Test: Jump to the median step, click next five times, click previous five times. )
		\item For each node, no space is occupied by fields that hold no value in neither the node itself nor it's tooltip.
		\item The ids of the nodes start at one and are continuous. If the test application is started again with the exact same inputs, the each node has the same id as in the last execution.
		\item The source code tooltips show and highlight the corresponding lines of code. (Test: If possible, choose two nodes, one that corresponds to the middle of a chain of reactive function calls and one that corresponds to the end of a chain of reactive function calls. For both nodes check if the highlighting is correct.)
		\item The node or edge that was updated in a step is highlighted. (Test: Check for the first ten steps in the history.)
		\item The history queries can be used to search for a specific event in the history. (Test: evaluationYielded and nodeUpdated find the corresponding steps for the first named node.)
		\item The graph can be searched, the matching node(s) is/are highlighted and if the search is reseted the original view will be restored. (Test: Search for the dependencies of a node and then reset the search.)
		\item Reactive breakpoints can be used to pause the debugger when a specific event occurs. (Test: A breakpoint set for the first node created will break at step one. A breakpoint for the first node updated will break before the value is updated in the observable.)
	\end{itemize}
	Results in abstract - Detailed result tables in appendix.
	% - short mention of excluded tests:
		% RxJS/all-operators - artifical examples by Pradeep Baradur used to verify operators but not a suitable test application.
		% RxJS/spotify-search - great test application in general, but the used API does not work without a token.
	% findings:
	% - statistical results: For this statistic spec 9 was interpreted as two different results to have a simple result with Yes and No's - Ambiguity was counted as No because it means not fully supported yet. N.A. was counted as Yes because it does no additional work to be done by a dev
		% verified 388/420 working
		% specs 2,3,4,5,6,9.2 are without errors in any application
	% Exceptions in detail:
	% - N.A. mostly not applicable because there were no named nodes
	% - different classes of errors or details of a single error AND if they were present in CRI2: 
		% - Ambiguity: CRI can not handle nodes with the same name. e.g. a named node created in a for loop. CRI will use the first or last node depending on the context and is not equipped to handle ambiguous names consitently yet. Dependencies can not be found correctly, history queries will only match one node. # verified CRI2 with split file test
		% - spec 9 : N*,Y - the nodes are added out of order in RxJS if the first node does not stem from jalangi analysis. #verified CRI2 with son_father_wallet
		% - Dependencies or Dependents not correctly highlighted: seems to be related to dynamically created nodes, but not always. Is a bug. # different behavior with CRI2 crop example - new bug, equal behavior with stopwatch example.
		% - alphabetinvasion: observables are not correctly recorded. The test uses closures and custom operators (although custom operators do work in RxJS\animationtest). Example observable that is missing!!! # verified with CRI2
		% - BaconJS/blog-url the named variable is not correctly detected, futhermore the bacon recording does not detect the correct observables. # verified with CRI2
	%  They should be the target of further development.